\documentclass[a4paper,12pt]{report}
\usepackage{titling}
\begin{document}
\begin{titlepage}
	\begin{center}
	\title{Development of an OTA (Over the Air) Mobile Learning Telepresence Platform}
	\textsc{\Large MSc (Project/Thesis) Proposal}
	\textsc{by}
	\textsc{\Large Kyle Galvin}
	\textsc{\Large Computer Science Department, Lakehead University}
	\textsc{\Large  Supervisor: Jinan Fiaidhi and Sabah Mohammed}
	\textsc{\Large HBSc Computer Science, Lakehead University, 2013}
	\textsc{\Large A Thesis Submitted in Partial Fulfillment of the Requirements for the Degree of}

	\textsc{\Large MSC COMPUTER SCIENCE}

	\textsc{\Large in the department of Computer Science}


	\textsc{Copyright Kyle Galvin, 2013}
	\textsc{Lakehead University}
	\textsc{All rights reserved. This thesis may not be reproduced in whole or in part, py photocopy or other means, without the permission of the author.}
	\end{center}
\end{titlepage}

\maketitle

\tableofcontents

\chapter*{\centering Abstract}
Telepresence has been used in many forms in academia university for more than a decade by now as entities that help to maintain the relationship with learners and provide them with collaborative experiences without the expense of physical travel. However, the emerging technology has shifted its focus from the large class-room telepresence equipment’s to be scaled- down to mobile, wireless-networked telepresence products. With this technology shift, we are required to provide the learner with the ubiquitous ability to explore core learning contents deployed over the internet as well as to enable learners to interact with many other remote physical learning environments (e.g., Web environments, instructors, colleagues) through the use of mobile devices. This project aims at exploring this research area and to come with a solution for implementing a new type of learning objects that can be used over the air for telecollaboration and telepresence suitable for mobile platforms. 

\chapter{Lightweight Telepresence Technologies}

Microprocessors have shaped the world over the last century. Reducing in size over time exponentially, we are now able to achieve things that would have been unimaginable in the past. We can squeeze more bits per volume, transport more information and crunch more data each second than ever before. With this explosion of portability and connectivity comes a renaissance of technological growth that is unfolding before our eyes.

Density of information and computation as well as the speed of communication are at the core of modern digital technology, yet focusing on these features displays a very hands-on white box approach. There is also much to be learned with respect to the interaction between digital components and their environments, which could be considered more of a black box "I/O" style description. The interface a device supplies for others to interact with is just as important as the computational and communicative abilities the device has intenally to process the environment around it.

By extrapolating on current computational growth trends, we can imagine many applications in which technology will soon improve our every day lives. By studying these applications both mundane and whimsical alike, we are likely to find many exciting ideas which are attainable much more immediately than they first appeared.

Arthur C. Clarke once wrote "Any sufficiently advanced technology is indistinguishable from magic". Indeed many amazing discoveries can find roots in sci-fi and futuristic predictions which push the boundaries of our collective knowlege and explore the potential and logical conclusions of current technological progress. The most recent ideas which are moving from science fiction to science fact are telepresence and augmented reality. 

To introduce these ideas, I will borrow from the definitions others have supplied:
\begin{quotation}
Telepresence systems provide a human operator with the feeling of actual presence in a remote environment, the target environment. The feeling of presence is achieved by visual and acoustic sensory information recorded from the target environment and presented to the user on an immersive display.
	\begin{flushright}
		\cite{6094998}
	\end{flushright}
\end{quotation}
\begin{quotation}
AR is a variation of the more known concept of Virtual Reality Technology (VR), which is often defined as “the use of real-time digital computers and other special hardware and software to generate a simulation of an alternate world or environment, which is believable as real or true by the users”. VR technology creates an environment in which the user feels and seems to be moving inside a computer-created virtual world in the same way people move inside natural environment; while immersed in the virtual world, the user cannot perceive the real one which still surrounds him. On the contrary, AR allows the user to see the real world, augmenting it with superimposed virtual objects. In other words, while VR replaces reality, AR supplements it, creating an environment in which real and virtual objects harmonically coexist.
	\begin{flushright}
		\cite{5970856}
	\end{flushright}
\end{quotation}

\section{Emerging Mobile Technologies}
As microchip density increases, so does the mobility of computational and processing devices. While PDA and handheld gaming devices have been around for decades, the advance of cellular networks which allow for on-the-go personal telecommunications and widely dispersed access to internet services has really driven the shape and design of the current generation of mobile devices.

Smart phones and telecommunications aren't the only technology in this arena, but they are certainly the largest and most influential. Other devices to consider when discussing telepresence devices are lightweight microprocessors and system on a chip designs. These devices can allow industry and hobbiests alike to create a wide array of telepresence hardware that is capable of interacting with the environment around it on another's behalf. In this case, we are now less bound by strict computational limits and are now merely bound by the sensors, motors, and analog/digital conversions available to read from (and interact with) the environment around us.

When we combine our new-found freedom to invent any sort of sensory device with our fully connected and always online 'internet of things', we can begin to explore and create all sorts of ideas that were inaccessable to the real-world and thus bound to the realm of fiction, futurism, and sci-fi.
\subsection{Microcontrollers \& customized System on a Chip (SoaC) components}

\begin{quotation}{
	...the BCI collects the EEG brain activity and decodes the user's intentions, which are transferred to the robot via the Internet. The robot autonomously executes the orders using the navigation system (implemented with a combination of dynamic online grid maping with scan matching, dynamic path planning, and obstacle avoidance) or the camera orientation system. Thus, the shared-control strategy is built by means  of the mental selection of robot navigation or active visual exploration task-related orders, which can be autonomously executed by the robot.}
	\begin{flushright}
		\cite{6104414}
	\end{flushright}
\end{quotation}
\begin{quote}
	Traditionally most robotic applications have involved the use of single static (non-mobile) manipulator platforms, with this technique being particularly suited to applications where the actual task is relatively well defined, the work volume is limited and safety considerations make even slightly “unexpected” motions totally unacceptable.
	\begin{flushright}
		\cite{540147}
	\end{flushright}
\end{quote}
\begin{quote}
In this telepresence domain, as remote manipulators become more sophisticated and the tasks they undertake become more complex. Three main sensory obstacles to effective widespread use have been identified [15]:
	\begin{enumerate}
		\item The detection of sensory signals
		\item The feedback of real-time sensory information to the operator
		\item The presentation of this information in a form that can be easily detected, processed by the brain as a reflex action and responded to, since an excessive need for thought would detract from performance of the primary task.
	\end{enumerate}
	\begin{flushright}
		\cite{540147}
	\end{flushright}
\end{quote}

\begin{quote}

The main objective of tele-robotics has been to develop methodologies for the control of robots at remote sites by human users at local sites. Tele-robots are suitable in certain situations such as:
\begin{enumerate}
\item The robot must operate in environments that are hazardous to human health.
\item The robot must operate at a scale that is much smaller or larger than the human size and scale.
\item The robot must operate in a location where it would be too costly for the human to be present (in terms of budget, timing requirements, and human safety).
\end{enumerate}
	\begin{flushright}
		\cite{726589}
	\end{flushright}
\end{quote}

The idea of presence fidelity can be considered a continuum. We can consider verbal descriptions and printed material on the low-fidelity end of the spectrum, while actual presence would be on the highest end. Our goal is to bring virtual telepresence farther along this continuum until it is as close to actual presence as possible \cite{726589}

\subsection{Mobile phones \& Cellular devices}
\cite{4469080}
\cite{6001904}
\cite{6007847}
\section{Telepresence \& Real-Time communications}
\subsection{Audio/Video compression}
\cite{4297087}
\cite{4801602}
\cite{5054795}
\subsection{Cellular network bandwidth flow \& optimization}
\cite{5710522}
\cite{1300874}
\cite{1376696}
\subsection{Privacy}
\cite{4698190}
\cite{4471983}
\cite{6270872}
\cite{1032602}
\section{Digital identification and modeling}
\subsection{Bar codes \& QR codes}
QR codes (or two-dimensional bar codes) can reference nearly anything. Ranging in size from 25x25 to 177x177, they are most often used to redirect a user to a URL containing anything from videos to product info to social media content \cite{6182398}
Basic compression is done using run-length coding, where sequences of identical values are replaced with a single instance of that value followed by the repetition count. \cite{6182398}
\subsection{RFID; NFC}
\cite{5340296}
\subsection{real-time digital modeling}
\subsubsection{Stitching multiple images/videos together}
In cases where images are not aligned, unwanted artifacts can be produced. Color and lighting inconsistencies can also be introduced which would create an unbalanced effect. A lack of references and identifiable control points can also make it difficult to correctly position image fragments. \cite{4359344}

\cite{5397590}
\subsubsection{Depth matricies/maps for 3D imaging}
Depth imaging techniques have only previously existed in costly special-purpose applications. With the spread of large-scale production on Time-Of-Flight sensors (specifically, the Microsoft Kinect) the accessability and spread of these devices has grown considerably. Time-Of-Flight technology involves measuring the delay between sending and recieving an infared signal. With this information, triangulation techniques can be used to measure the depth between the device and the target. 

These devices have been designed with object recognition in mind and are not particularly suited for 3d scanning applications. Low resolution and a large amount of noise are certainly factors when re-purposing these technologies for scanning\cite{6296662} 
\subsection{Image recognition and classification}
Image recognition is a complex problem often approached with a neural network model or similar fuzzy categorical organizer. If RGB information is augmented with depth information we can achieve much better results than if we were to rely on RGB information alone.
\subsubsection{Vector Quantization}
\subsubsection{Uncertainty / Fuzzy Logic}
\subsubsection{Improved accuracy through domain-specific environments/contexts}
telepresence surgery model - live data can be collected, then used to simulate the procedure virtually. 
This effectively allows us to generate training programs which are extremely accurate within the domain of the live collected data.

Imagine a doctor in front of device operates instrumentation which performs surgery on a remote patient.
instrumentation includes a wide variety of I/O (controls and sensory output via microphone, video, and even tactic feedback)
Assume access to highly detailed descriptions of our I/O over the duration of many operations (live experience captures)
The challenge is to make a virtual model of the operating procedure in which the doctor can interact with a virtual patient in a way which is synonymous with the standard interactions they would encounter with a live patient.

The challenge is considered 'solved' when the doctor cannot differentiate between a live patient telepresence experience and a simulated patient telepresence experience
I call this challenge the "Telepresence Turing Test", and it can be applied to any activity or domain in which telepresence can augment.

This challenge has a few interesting unknowns.

How 'synonymous' with live data can we realistically make the experience?

What are the most important factors we need to capture in our training data? What instrumentation can best capture those factors?

From the training data (live experience captures), how can we best create and improve upon a simulation model?\cite{391769} 

\bibliography{mastersthesis}
\bibliographystyle{alpha}
\end{document}
