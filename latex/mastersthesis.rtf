{\rtf1\ansi\uc1\deff0\deflang1024
{\fonttbl{\f0\fnil\fcharset0 Times New Roman;}
{\f1\fnil\fcharset0 Arial;}
{\f2\fnil\fcharset0 Arial;}
{\f3\fnil\fcharset0 Courier New;}
{\f4\fnil\fcharset0 Zapf Chancery;}
{\f5\fnil\fcharset0 STIXGeneral;}
}
{\colortbl;
\red0\green0\blue0;
\red0\green0\blue255;
\red0\green255\blue255;
\red0\green255\blue0;
\red255\green0\blue255;
\red255\green0\blue0;
\red255\green255\blue0;
\red255\green255\blue255;
}
{\stylesheet
{\s0\qj\widctlpar\f0\fs24 \snext0 Normal;}
{\cs10 \additive\ssemihidden Default Paragraph Font;}
{\s1\qc\sb240\sa120\keepn\f0\b\fs40 \sbasedon0\snext0 Part;}
{\s2\ql\sb240\sa120\keepn\f0\b\fs40 \sbasedon0\snext0 heading 1;}
{\s3\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext0 heading 2;}
{\s4\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext0 heading 3;}
{\s5\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 4;}
{\s6\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 5;}
{\s7\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 6;}
{\s8\qr\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext8 rightpar;}
{\s9\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext9 centerpar;}
{\s10\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext10 leftpar;}
{\s11\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equation;}
{\s12\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationNum;}
{\s13\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationAlign;}
{\s14\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationAlignNum;}
{\s15\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationArray;}
{\s16\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationArrayNum;}
{\s17\ql\sb120\sa120\keep\widctlpar\f0\fs20 \sbasedon0\snext0 theorem;}
{\s18\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 bitmapCenter;}
{\s20\qc\sb240\sa240\b\f0\fs36 \sbasedon0\snext21 Title;}
{\s21\qc\sa120\f0\fs24 \sbasedon0\snext0 author;}
{\s22\ql\tqc\tx4536\tqr\tx9072\f0\fs20 \sbasedon0\snext22 footer;}
{\s23\ql\tqc\tx4536\tqr\tx9072\f0\fs20 \sbasedon0\snext23 header;}
{\s30\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 caption;}
{\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext0 Figure;}
{\s32\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext32 Table;}
{\s33\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext33 Tabular;}
{\s34\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext34 Tabbing;}
{\s35\qj\li1024\ri1024\fi340\widctlpar\f0\fs20 \sbasedon0\snext35 Quote;}
{\s38\ql\widctlpar\f3\fs24 \snext38 verbatim;}
{\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext46 List;}
{\s47\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext47 List 1;}
{\s50\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 latex picture;}
{\s51\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 subfigure;}
{\s61\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext62 bibheading;}
{\s62\ql\fi-567\li567\sb0\sa0\f0\fs20 \sbasedon0\snext62 bibitem;}
{\s64\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext64 endnotes;}
{\s65\ql\fi-113\li397\lin397\f0\fs24 \sbasedon0\snext65 footnote text;}
{\s66\qj\fi-170\li454\lin454\f0\fs24 \sbasedon0\snext66 endnote text;}
{\cs62\super \additive\sbasedon10 footnote reference;}
{\cs63\super \additive\sbasedon10 endnote reference;}
{\s67\ql\sb60\sa60\keepn\f0\fs24 \sbasedon0\snext67 acronym;}
{\s70\qc\sa120\b\f0\fs24 \sbasedon0\snext71 abstract title;}
{\s71\qj\li1024\ri1024\fi340\widctlpar\f0\fs24 \sbasedon0\snext0 abstract;}
{\s80\ql\sb240\sa120\keepn\f0\b\fs20 \sbasedon0\snext0 contents_heading;}
{\s81\ql\li425\tqr\tldot\tx8222\sb240\sa60\keepn\f0\fs24\b \sbasedon0\snext82 toc 1;}
{\s82\ql\li512\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs24 \sbasedon0\snext83 toc 2;}
{\s83\ql\li1024\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs24 \sbasedon0\snext84 toc 3;}
{\s84\ql\li1536\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs24 \sbasedon0\snext85 toc 4;}
{\s85\ql\li2048\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs24 \sbasedon0\snext86 toc 5;}
{\s86\ql\li2560\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs24 \sbasedon0\snext86 toc 6;}
}
{\info
{\title Original file was mastersthesis.tex}
{\doccomm Created using latex2rtf 2.3.3 r1230 (released Feb 26, 2013) on Wed Jun 12 18:05:31 2013
}
}
{\footer\pard\plain\f0\fs24\qc\chpgn\par}
\paperw11960\paperh16900\margl2500\margr2560\margt2520\margb1820\pgnstart0\widowctrl\qj\ftnbj\f0\aftnnar
{{}\page
\pard\plain\s20\qc\sb240\sa240\b\f0\fs36\sl240\slmult1 \fi0 Development of an OTA (Over the Air) Mobile Learning Telepresence Platform\par
\pard\plain\s20\qc\sb240\sa240\b\f0\fs36\sl240\slmult1 \fi0 MSc (Project/Thesis) Proposal\par
\pard\plain\s21\qc\sa120\f0\fs24\sl240\slmult1 \fi360 Kyle Galvin\par
\pard\plain\s21\qc\sa120\f0\fs24\sl240\slmult1 \fi0 Computer Science Department, Lakehead University\par
\pard\plain\s21\qc\sa120\f0\fs24\sl240\slmult1 \fi0 Supervisor: Jinan Fiaidhi and Sabah Mohammed\par
\pard\plain\s21\qc\sa120\f0\fs24\sl240\slmult1 \fi360 \chdate \par
\pard\plain\s80\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \fi0  Contents\par
\pard\plain\s0\qj\widctlpar\f0\fs24\sl240\slmult1 \fi0 \par
{\field{\*\fldinst TOC \\o "1-3" }{\fldrslt }}
\page
\pard\plain\ql\sb240\sa120\keepn\f0\b\fs40\sl240\slmult1 \sb60 \fi0 Chapter\par
\pard\plain\s2\ql\sb240\sa120\keepn\f0\b\fs40\sl240\slmult1 \sb240 \fi0 \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 Abstract\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb240 \fi360 Telepresence has been used in many forms in academia university for more than a decade by now as entities that help to maintain the relationship with learners and provide them with collaborative experiences without the expense of physical travel. However, the emerging technology has shifted its focus from the large class-room telepresence equipment\u226?\u8364?\u8482?s to be scaled- down to mobile, wireless-networked telepresence products. With this technology shift, we are required to provide the learner with the ubiquitous ability to explore core learning contents deployed over the internet as well as to enable learners to interact with many other remote physical learning environments (e.g., Web environments, instructors, colleagues) through the use of mobile devices. This project aims at exploring this research area and to come with a solution for implementing a new type of learning objects that can be used over the air for telecollaboration and telepresence suitable for mobile platforms. \par
\pard\plain\ql\sb240\sa120\keepn\f0\b\fs40\sl240\slmult1 \fi0 Chapter 1\par
\pard\plain\s2\ql\sb240\sa120\keepn\f0\b\fs40\sl240\slmult1 \sb240 \fi0 Lightweight Telepresence Technologies\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb240 \fi0 Microprocessors have shaped the world over the last century. Reducing in size over time at an exponential rate, we are now able to achieve things that would have been unimaginable in the past. We can squeeze more bits per volume, transport more bits and calculate more atomic operations per time than ever before. With this explosion of portability and connectivity comes a renaissance of technological growth that is unfolding before our eyes.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 Density of information and computation as well as the speed of communication are at the core of modern digital technology, yet focusing on these features displays a very hands-on white box approach. There is also much to be learned with respect to the interaction between digital components and their environments, which could be considered more of a black box "I/O" style description. The interface a device is engineered to supply is just as important as the computational and communicative abilities the device has to process the environment around it.\par
{\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \li512\ri512\fi360 Telepresence systems provide a human operator with the feeling of actual presence in a remote environment, the target environment. The feeling of presence is achieved by visual and acoustic sensory information recorded from the target environment and presented to the user on an immersive display. {\par

\pard\plain\s8\qr\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \li512\ri512\fi0 [{\field{\*\fldinst{\lang1024 REF BIB_6094998 \\* MERGEFORMAT }}{\fldrslt{4}}}
] \par
}}\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb300 \fi0 1.1  Emerging Mobile Technologies\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 As microchip density increases, so does the mobility of computational and processing devices. While PDA and handheld gaming devices have been around for decades, the advance of cellular networks which allow for on-the-go personal telecommunications and widely dispersed access to internet services has really driven the shape and design of the current generation of mobile devices.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 Smart phones and telecommunications aren\rquote t the only technology in this arena, but they are certainly the largest and most influential. Other devices to consider when discussing telepresence devices are lightweight microprocessors and system on a chip designs. These devices can allow industry and hobbiests alike to create a wide array of telepresence hardware that is capable of interacting with the environment around it on another\rquote s behalf. In this case, we are now less bound by strict computational limits and are now merely bound by the sensors, motors, and analog/digital conversions available to read from (and interact with) the environment around us.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 When we combine our new-found freedom to invent any sort of sensory device with our fully connected and always online \rquote internet of things\rquote , we can begin to explore and create all sorts of ideas that were inaccessable to the real-world and thus bound to the realm of fiction, futurism, and sci-fi. \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.1.1  Microcontrollers & customized System on a Chip (SoaC) components\par
{\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb120 \li512\ri512\fi0 { ...the BCI collects the EEG brain activity and decodes the user\rquote s intentions, which are transferred to the robot via the Internet. The robot autonomously executes the orders using the navigation system (implemented with a combination of dynamic online grid maping with scan matching, dynamic path planning, and obstacle avoidance) or the camera orientation system. Thus, the shared-control strategy is built by means of the mental selection of robot navigation or active visual exploration task-related orders, which can be autonomously executed by the robot.} {\par

\pard\plain\s8\qr\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \li512\ri512\fi0 [{\field{\*\fldinst{\lang1024 REF BIB_6104414 \\* MERGEFORMAT }}{\fldrslt{9}}}
] \par
}}{\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb120 \li512\ri512\fi360 Traditionally most robotic applications have involved the use of single static (non-mobile) manipulator platforms, with this technique being particularly suited to applications where the actual task is relatively well defined, the work volume is limited and safety considerations make even slightly \u226?\u8364?\u339?unexpected\u226?\u8364?\u32? motions totally unacceptable. {\par

\pard\plain\s8\qr\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \li512\ri512\fi0 [{\field{\*\fldinst{\lang1024 REF BIB_540147 \\* MERGEFORMAT }}{\fldrslt{6}}}
] \par
}}{\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb120 \li512\ri512\fi360 In this telepresence domain, as remote manipulators become more sophisticated and the tasks they undertake become more complex. Three main sensory obstacles to effective widespread use have been identified [15]: {\par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs24\sl240\slmult1 \sb50 \li1112\ri512\fi-300 1.\tab
The detection of sensory signals \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs24\sl240\slmult1 \sb50 \li1112\ri512\fi-300 2.\tab
The feedback of real-time sensory information to the operator \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs24\sl240\slmult1 \sb50 \li1112\ri512\fi-300 3.\tab
The presentation of this information in a form that can be easily detected, processed by the brain as a reflex action and responded to, since an excessive need for thought would detract from performance of the primary task. \par
}{
\pard\plain\s8\qr\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \li512\ri512\fi0 [{\field{\*\fldinst{\lang1024 REF BIB_540147 \\* MERGEFORMAT }}{\fldrslt{6}}}
] \par
}}{\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb120 \li512\ri512\fi360 The main objective of tele-robotics has been to develop methodologies for the control of robots at remote sites by human users at local sites. Tele-robots are suitable in certain situations such as: {\par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs24\sl240\slmult1 \sb50 \li1112\ri512\fi-300 1.\tab
The robot must operate in environments that are hazardous to human health. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs24\sl240\slmult1 \sb50 \li1112\ri512\fi-300 2.\tab
The robot must operate at a scale that is much smaller or larger than the human size and scale. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs24\sl240\slmult1 \sb50 \li1112\ri512\fi-300 3.\tab
The robot must operate in a location where it would be too costly for the human to be present (in terms of budget, timing requirements, and human safety). \par
}{
\pard\plain\s8\qr\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \li512\ri512\fi0 [{\field{\*\fldinst{\lang1024 REF BIB_726589 \\* MERGEFORMAT }}{\fldrslt{2}}}
] \par
}}\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi360 The idea of presence fidelity can be considered a continuum. We can consider verbal descriptions and printed material on the low-fidelity end of the spectrum, while actual presence would be on the highest end. Our goal is to bring virtual telepresence farther along this continuum until it is as close to actual presence as possible 
[{\field{\*\fldinst{\lang1024 REF BIB_726589 \\* MERGEFORMAT }}{\fldrslt{2}}}
]\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.1.2  Mobile phones & Cellular devices\par

\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 [{\field{\*\fldinst{\lang1024 REF BIB_4469080 \\* MERGEFORMAT }}{\fldrslt{11}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_6001904 \\* MERGEFORMAT }}{\fldrslt{7}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_6007847 \\* MERGEFORMAT }}{\fldrslt{5}}}
] \par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 1.2  Telepresence & Real-Time communications\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb180 \fi0 1.2.1  Audio/Video compression\par

\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 [{\field{\*\fldinst{\lang1024 REF BIB_4297087 \\* MERGEFORMAT }}{\fldrslt{20}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_4801602 \\* MERGEFORMAT }}{\fldrslt{16}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_5054795 \\* MERGEFORMAT }}{\fldrslt{3}}}
] \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.2.2  Cellular network bandwidth flow & optimization\par

\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 [{\field{\*\fldinst{\lang1024 REF BIB_5710522 \\* MERGEFORMAT }}{\fldrslt{13}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_1300874 \\* MERGEFORMAT }}{\fldrslt{14}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_1376696 \\* MERGEFORMAT }}{\fldrslt{15}}}
] \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.2.3  Privacy\par

\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 [{\field{\*\fldinst{\lang1024 REF BIB_4698190 \\* MERGEFORMAT }}{\fldrslt{22}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_4471983 \\* MERGEFORMAT }}{\fldrslt{21}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_6270872 \\* MERGEFORMAT }}{\fldrslt{17}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_1032602 \\* MERGEFORMAT }}{\fldrslt{18}}}
] \par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 1.3  Digital identification and modeling\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb180 \fi0 1.3.1  Bar codes & QR codes\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 QR codes (or two-dimensional bar codes) can reference nearly anything. Ranging in size from 25x25 to 177x177, they are most often used to redirect a user to a URL containing anything from videos to product info to social media content 
[{\field{\*\fldinst{\lang1024 REF BIB_6182398 \\* MERGEFORMAT }}{\fldrslt{1}}}
] Basic compression is done using run-length coding, where sequences of identical values are replaced with a single instance of that value followed by the repetition count. 
[{\field{\*\fldinst{\lang1024 REF BIB_6182398 \\* MERGEFORMAT }}{\fldrslt{1}}}
] \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.3.2  RFID; NFC\par

\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 [{\field{\*\fldinst{\lang1024 REF BIB_5340296 \\* MERGEFORMAT }}{\fldrslt{19}}}
] \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.3.3  real-time digital modeling\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb180 \fi0 Stitching multiple images/videos together\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 In cases where images are not aligned, unwanted artifacts can be produced. Color and lighting inconsistencies can also be introduced which would create an unbalanced effect. A lack of references and identifiable control points can also make it difficult to correctly position image fragments. 
[{\field{\*\fldinst{\lang1024 REF BIB_4359344 \\* MERGEFORMAT }}{\fldrslt{12}}}
]\par

\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 [{\field{\*\fldinst{\lang1024 REF BIB_5397590 \\* MERGEFORMAT }}{\fldrslt{23}}}
] \par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 Depth matricies/maps for 3D imaging\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 Depth imaging techniques have only previously existed in costly special-purpose applications. With the spread of large-scale production on Time-Of-Flight sensors (specifically, the Microsoft Kinect) the accessability and spread of these devices has grown considerably. Time-Of-Flight technology involves measuring the delay between sending and recieving an infared signal. With this information, triangulation techniques can be used to measure the depth between the device and the target. \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 These devices have been designed with object recognition in mind and are not particularly suited for 3d scanning applications. Low resolution and a large amount of noise are certainly factors when re-purposing these technologies for scanning
[{\field{\*\fldinst{\lang1024 REF BIB_6296662 \\* MERGEFORMAT }}{\fldrslt{8}}}
] \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.3.4  Image recognition and classification\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 Image recognition is a complex problem often approached with a neural network model or similar fuzzy categorical organizer. If RGB information is augmented with depth information we can achieve much better results than if we were to rely on RGB information alone. \par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 Vector Quantization\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb180 \fi0 Uncertainty / Fuzzy Logic\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb180 \fi0 Improved accuracy through domain-specific environments/contexts\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb60 \fi0 telepresence surgery model - live data can be collected, then used to simulate the procedure virtually. This effectively allows us to generate training programs which are extremely accurate within the domain of the live collected data.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 Imagine a doctor in front of device operates instrumentation which performs surgery on a remote patient. instrumentation includes a wide variety of I/O (controls and sensory output via microphone, video, and even tactic feedback) Assume access to highly detailed descriptions of our I/O over the duration of many operations (live experience captures) The challenge is to make a virtual model of the operating procedure in which the doctor can interact with a virtual patient in a way which is synonymous with the standard interactions they would encounter with a live patient.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 The challenge is considered \rquote solved\rquote  when the doctor cannot differentiate between a live patient telepresence experience and a simulated patient telepresence experience I call this challenge the "Telepresence Turing Test", and it can be applied to any activity or domain in which telepresence can augment.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 This challenge has a few interesting unknowns.\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 How \rquote synonymous\rquote  with live data can we realistically make the experience? \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 What are the most important factors we need to capture in our training data?  What instrumentation can best capture those factors? \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi360 From the training data (live experience captures), how can we best create and improve upon a simulation model? 
[{\field{\*\fldinst{\lang1024 REF BIB_391769 \\* MERGEFORMAT }}{\fldrslt{10}}}
] \par
{\pard\plain\s61\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 {\plain\b\fs32 Bibliography}\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \sb60 \li450\fi0 [{\v\*\bkmkstart BIB_6182398}1{\*\bkmkend BIB_6182398}]\tab
Hou A-Lin, Feng Yuan, and Geng Ying. {QR code image detection using run-length coding}. In {\i {Computer Science and Network Technology (ICCSNT), 2011 International Conference on}}, volume\~4, pages 2130\endash 2134, 2011.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_726589}2{\*\bkmkend BIB_726589}]\tab
A.\~Agah, R.\~Walker, and R.\~Ziemer. {A mobile camera robotic system controlled via a head mounted display for telepresence}. In {\i {Systems, Man, and Cybernetics, 1998. 1998 IEEE International Conference on}}, volume\~4, pages 3526\endash 3531 vol.4, 1998.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_5054795}3{\*\bkmkend BIB_5054795}]\tab
J.J. Ahmad, H.A. Khan, and S.A. Khayam. {Energy efficient video compression for wireless sensor networks}. In {\i {Information Sciences and Systems, 2009. CISS 2009. 43rd Annual Conference on}}, pages 629\endash 634, 2009.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_6094998}4{\*\bkmkend BIB_6094998}]\tab
A.P. Arias and U.D. Hanebeck. {Motion control of a semi-mobile haptic interface for extended range telepresence}. In {\i {Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on}}, pages 3053\endash 3059, 2011.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_6007847}5{\*\bkmkend BIB_6007847}]\tab
Huang Bin. {The study of Mobile Education development based on 3G technique and Cloud Computing}. In {\i {Uncertainty Reasoning and Knowledge Engineering (URKE), 2011 International Conference on}}, volume\~1, pages 86\endash 89, 2011.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_540147}6{\*\bkmkend BIB_540147}]\tab
D.\~Caldwell, A.\~Wardle, O.\~Kocak, and M.\~Goodwin. {Telepresence feedback and input systems for a twin armed mobile robot}. {\i Robotics Automation Magazine, IEEE}, 3(3):29\endash 38, 1996.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_6001904}7{\*\bkmkend BIB_6001904}]\tab
Jenyi Chao, Yen-Di Tzeng, Yi-Hsiu Lu, and Chuan-Hsi Liu. {The study of integrating PDA mobile learning device into the arts and Humanities Learning Curriculum for elementary schools #x2014;Mobile digital learning space}. In {\i {Multimedia Technology (ICMT), 2011 International Conference on}}, pages 6119\endash 6124, 2011.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_6296662}8{\*\bkmkend BIB_6296662}]\tab
Yan Cui, S.\~Schuon, S.\~Thrun, D.\~Stricker, and C.\~Theobalt. Algorithms for 3d shape scanning with a depth camera. {\i Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 35(5):1039\endash 1050, 2013.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_6104414}9{\*\bkmkend BIB_6104414}]\tab
C.\~Escolano, J.M. Antelis, and J.\~Minguez. {A Telepresence Mobile Robot Controlled With a Noninvasive Brain #x2013;Computer Interface}. {\i Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on}, 42(3):793\endash 804, 2012.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_391769}10{\*\bkmkend BIB_391769}]\tab
P.S. Green, J.W. Hill, J.F. Jensen, and A.\~Shah. {Telepresence surgery}. {\i Engineering in Medicine and Biology Magazine, IEEE}, 14(3):324\endash 329, 1995.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_4469080}11{\*\bkmkend BIB_4469080}]\tab
W.\~Hosny. {Power engineering mobile education technology}. In {\i {Universities Power Engineering Conference, 2007. UPEC 2007. 42nd International}}, pages 971\endash 974, 2007.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_4359344}12{\*\bkmkend BIB_4359344}]\tab
Jiaya Jia and Chi-Keung Tang. {Image Stitching Using Structure Deformation}. {\i Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 30(4):617\endash 631, 2008.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_5710522}13{\*\bkmkend BIB_5710522}]\tab
S.\~Kim. {Cellular network bandwidth management scheme by using nash bargaining solution}. {\i Communications, IET}, 5(3):371\endash 380, 2011.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_1300874}14{\*\bkmkend BIB_1300874}]\tab
Sungwook Kim and P.K. Varshney. {An integrated adaptive bandwidth-management framework for QoS-sensitive multimedia cellular networks}. {\i Vehicular Technology, IEEE Transactions on}, 53(3):835\endash 846, 2004.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_1376696}15{\*\bkmkend BIB_1376696}]\tab
Kam-Yiu Lam, Joe Yuen, and E.\~Chan. {On using buffered bandwidth to support real-time mobile video playback in cellular networks}. In {\i {Multimedia Software Engineering, 2004. Proceedings. IEEE Sixth International Symposium on}}, pages 466\endash 473, 2004.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_4801602}16{\*\bkmkend BIB_4801602}]\tab
Limin Liu, Zhen Li, and E.J. Delp. {Efficient and Low-Complexity Surveillance Video Compression Using Backward-Channel Aware Wyner-Ziv Video Coding}. {\i Circuits and Systems for Video Technology, IEEE Transactions on}, 19(4):453\endash 465, 2009.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_6270872}17{\*\bkmkend BIB_6270872}]\tab
Xinxin Liu and Xiaolin Li. {Privacy Preserving Techniques for Location Based Services in Mobile Networks}. In {\i {Parallel and Distributed Processing Symposium Workshops PhD Forum (IPDPSW), 2012 IEEE 26th International}}, pages 2474\endash 2477, 2012.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_1032602}18{\*\bkmkend BIB_1032602}]\tab
Sang\~Yun Park, Moon\~Seog Han, and Young\~Ik Eom. {An efficient authentication protocol supporting privacy in mobile computing environments}. In {\i {High Speed Networks and Multimedia Communications 5th IEEE International Conference on}}, pages 332\endash 334, 2002.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_5340296}19{\*\bkmkend BIB_5340296}]\tab
R.\~Pathak and S.\~Joshi. {Recent trends in RFID and a java based software framework for its integration in mobile phones}. In {\i {Internet, 2009. AH-ICI 2009. First Asian Himalayas International Conference on}}, pages 1\endash 5, 2009.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_4297087}20{\*\bkmkend BIB_4297087}]\tab
Zhao Shu-long, You Zhi-Sheng, Lan Shi-yong, and Zhou Xin. {An Improved Video Compression Algorithm for Lane Surveillance}. In {\i {Image and Graphics, 2007. ICIG 2007. Fourth International Conference on}}, pages 224\endash 229, 2007.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_4471983}21{\*\bkmkend BIB_4471983}]\tab
Caimu Tang and D.O. Wu. {Mobile Privacy in Wireless Networks-Revisited}. {\i Wireless Communications, IEEE Transactions on}, 7(3):1035\endash 1042, 2008.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_4698190}22{\*\bkmkend BIB_4698190}]\tab
Lei Tang, S.\~Vrbsky, and Xiaoyan Hong. {Collaborated Camouflaging Mobility for Mobile Privacy}. In {\i {Global Telecommunications Conference, 2008. IEEE GLOBECOM 2008. IEEE}}, pages 1\endash 5, 2008.\par
\pard\plain\s62\ql\fi-567\li567\sb0\sa0\f0\fs20\sl240\slmult1 \li450\fi0 [{\v\*\bkmkstart BIB_5397590}23{\*\bkmkend BIB_5397590}]\tab
Yingen Xiong and K.\~Pulli. {Sequential image stitching for mobile panoramas}. In {\i {Information, Communications and Signal Processing, 2009. ICICS 2009. 7th International Conference on}}, pages 1\endash 5, 2009.\par
}}}
